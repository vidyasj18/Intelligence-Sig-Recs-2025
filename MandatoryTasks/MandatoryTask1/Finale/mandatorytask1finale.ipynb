{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b096776-a8d5-4f33-b055-3f51e904519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building machine learning system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a47554-e76e-41c8-bb63-d532e0035ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d0c18b6-278b-42ea-b97d-b5a396352be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (2.20.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (2.2.5)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (6.31.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (80.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (4.13.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (1.75.1)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
      "Requirement already satisfied: pillow in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.2.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
      "Requirement already satisfied: namex in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\vidya\\appdata\\roaming\\python\\python313\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a4ce8c-c702-482f-9ac6-ca80c75f956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0836b0d-453e-4913-95b6-8a2e4567b63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VIDYA\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\VIDYA\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\VIDYA\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\VIDYA\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\VIDYA\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\VIDYA\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\VIDYA\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\VIDYA\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\VIDYA\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\VIDYA\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\VIDYA\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\VIDYA\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\VIDYA\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\VIDYA\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\VIDYA\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\VIDYA\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\VIDYA\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\VIDYA\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\VIDYA\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\VIDYA\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Bidirectional, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53bbfaa-2354-4a84-8ab7-0b30b62ba4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying out on some example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14a0b5d-5569-440a-9e92-2b7450e0a1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing an example data to test on - pattern is similar to the newsQA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b668e87-7214-4f92-8c89-09741ab3c5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce65137a-0317-4ee9-98cb-e6d6d7b65cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "Python is a high-level, interpreted programming language.\n",
    "It was created by Guido van Rossum and first released in 1991.\n",
    "It is widely used for web development, data science, AI, and more.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0001c97c-e498-49e4-8390-7101cfaedf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# english questions and english answers - this is example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "047d6cf4-87a4-4ba2-8f93-5ea1388789ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"Who created Python?\",\n",
    "    \"When was Python first released?\",\n",
    "    \"What is Python used for?\"\n",
    "]\n",
    "\n",
    "answers_en = [\n",
    "    \"Guido van Rossum\",\n",
    "    \"1991\",\n",
    "    \"web development data science AI and more\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6528cd7f-8c5c-49f1-8386-cc5a1bff3079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# english answer is to be translated to french"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d6cf14a-b66e-4eaf-8255-3878fda08828",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_fr = [\n",
    "    \"Guido van Rossum\",\n",
    "    \"1991\",\n",
    "    \"développement web science des données IA et plus\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de86317b-d142-4505-b92e-edf1c81c6f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the text - coverting the letters in lower letters, removing numbers, symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3670387a-066b-4880-8cba-e8f5350ac0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def processed_text(text):\n",
    "    text = text.lower()  # lowercase\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ba7ba2b-e60d-4d04-b28b-009f72b4de81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npython is a highlevel interpreted programming language\\nit was created by guido van rossum and first released in 1991\\nit is widely used for web development data science ai and more\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_text(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "681492be-b952-43d3-b770-431334ecf9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_clean = processed_text(context)\n",
    "questions_clean = [processed_text(q) for q in questions]\n",
    "answers_clean = [processed_text(a) for a in answers_en]\n",
    "answers_fr_clean = [processed_text(a) for a in answers_fr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7db6b60-ad12-4bb2-af9c-0a44e4da40ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npython is a highlevel interpreted programming language\\nit was created by guido van rossum and first released in 1991\\nit is widely used for web development data science ai and more\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90b4e345-ebc5-4c53-95cc-f4a4ba064d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['who created python',\n",
       " 'when was python first released',\n",
       " 'what is python used for']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "229f1cae-c01d-4e6f-a323-6206d5d88cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['guido van rossum', '1991', 'web development data science ai and more']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f97cd65d-1ebb-4012-9198-794b042b1be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['guido van rossum',\n",
       " '1991',\n",
       " 'développement web science des données ia et plus']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_fr_clean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbcc126-cf18-4c22-9d2b-cccf1b29c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokanizers - used from PART A of mandatory task 1 - using embedding layers and neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79e5f402-ffb4-4984-a213-31fae03eb383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "processed_texts = [\n",
    "    context_clean,                \n",
    "] + questions_clean + answers_clean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45c42bf5-a000-4fb1-8b17-753205d6e52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\npython is a highlevel interpreted programming language\\nit was created by guido van rossum and first released in 1991\\nit is widely used for web development data science ai and more\\n',\n",
       " 'who created python',\n",
       " 'when was python first released',\n",
       " 'what is python used for',\n",
       " 'guido van rossum',\n",
       " '1991',\n",
       " 'web development data science ai and more']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6782b73d-dc78-430a-9688-66d4b7d4cdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the layer using tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93280306-e0c0-44f3-98e2-decdb6d38487",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = TfidfVectorizer(max_features=100)  \n",
    "X_layer = layer.fit_transform(processed_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cbfb0e5-a07a-4298-a3e9-4b8a0021902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_words = layer.get_feature_names_out()\n",
    "layer_vectors = X_layer.toarray().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63a42d3c-bdb5-431d-9f3f-fd4da5826629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1991', 'ai', 'and', 'by', 'created', 'data', 'development',\n",
       "       'first', 'for', 'guido', 'highlevel', 'in', 'interpreted', 'is',\n",
       "       'it', 'language', 'more', 'programming', 'python', 'released',\n",
       "       'rossum', 'science', 'used', 'van', 'was', 'web', 'what', 'when',\n",
       "       'who', 'widely'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5492c0-43b7-4b00-b53e-084079d5a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA model - provides answer in english - code is used from the part C mandatory task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6a1eca-1018-4caa-a2e6-db95f2c8d3ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b2f9fa6-99f8-489a-9ad6-a9e8e4374040",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch\n",
    "\n",
    "MODEL = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "tokenizer_qa = AutoTokenizer.from_pretrained(MODEL)\n",
    "qa_model = AutoModelForQuestionAnswering.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a2ef22c-aae9-4eb5-9c31-70cb11b64ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_english(question, context):\n",
    "    \"\"\"\n",
    "    Input: English question + context\n",
    "    Output: Predicted English answer\n",
    "    \"\"\"\n",
    "    inputs = tokenizer_qa(question, context, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = qa_model(**inputs)\n",
    "    \n",
    "    start_index = torch.argmax(outputs.start_logits)\n",
    "    end_index = torch.argmax(outputs.end_logits) + 1  # include last token\n",
    "    \n",
    "    answer_tokens = inputs[\"input_ids\"][0][start_index:end_index]\n",
    "    answer = tokenizer_qa.decode(answer_tokens)\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f494aa-4194-4f65-be34-47d42b85a3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using this on our example given above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ebbcf2a-797f-415b-bc86-a6289341697d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Who created Python?\n",
      "A: guido van rossum\n",
      "Q: When was Python first released?\n",
      "A: 1991\n",
      "Q: What is Python used for?\n",
      "A: web development, data science, ai, and more\n"
     ]
    }
   ],
   "source": [
    "for q in questions:\n",
    "    ans = get_answer_english(q, context)\n",
    "    print(f\"Q: {q}\")\n",
    "    print(f\"A: {ans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76871de2-f4ca-4870-af37-1b804b4bbd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translation model from english to french - code is used from part B mandatory task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92cf55aa-6d28-43f9-b03c-d6dff76f3224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cfbaead3-cf37-411b-9a37-300b9f8fb837",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = keras.preprocessing.text.Tokenizer(filters='')\n",
    "tokenizer_en.fit_on_texts([a.lower() for a in answers_en])\n",
    "input_tensor = tokenizer_en.texts_to_sequences([a.lower() for a in answers_en])\n",
    "input_tensor = keras.utils.pad_sequences(input_tensor, padding='post')\n",
    "\n",
    "tokenizer_fr = keras.preprocessing.text.Tokenizer(filters='')\n",
    "tokenizer_fr.fit_on_texts([a.lower() for a in answers_fr])\n",
    "target_tensor = tokenizer_fr.texts_to_sequences([a.lower() for a in answers_fr])\n",
    "target_tensor = keras.utils.pad_sequences(target_tensor, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60253c52-dd1d-41a9-b51a-310ec3bf5f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ee63d94-46f6-4f8a-80a4-a014293a72f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 64\n",
    "units = 128\n",
    "vocab_inp_size = len(tokenizer_en.word_index) + 1\n",
    "vocab_tar_size = len(tokenizer_fr.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3110d82e-add7-4502-a348-86f5513f1029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3a33236-888b-4347-b24f-73dc0f706718",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = keras.Input(shape=(None,))\n",
    "enc_emb = layers.Embedding(vocab_inp_size, embedding_dim, mask_zero=True)(encoder_inputs)\n",
    "encoder_lstm = layers.LSTM(units, return_state=True)\n",
    "_, state_h, state_c = encoder_lstm(enc_emb)\n",
    "encoder_states = [state_h, state_c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc8a7e6-dd46-478c-be01-6b4ab0a42dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da558d48-ecc8-46f9-b90f-ffe3c3c811e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = keras.Input(shape=(None,))\n",
    "dec_emb_layer = layers.Embedding(vocab_tar_size, embedding_dim, mask_zero=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "decoder_lstm = layers.LSTM(units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "decoder_dense = layers.Dense(vocab_tar_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4b3267-e21d-4ffd-ab42-cab8b543547a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a644ddc-5401-4d60-9933-7e69fd2246bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39b9c864-0fc8-4493-bd76-84ae4e6ecd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_data = target_tensor[:, :-1]\n",
    "decoder_target_data = target_tensor[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fdb029-4b9d-49f7-9257-f02c4f23512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training on smaller dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06431197-d020-4e2a-b3d6-fedc9d07d3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x26d76f8aba0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([input_tensor, decoder_input_data], decoder_target_data, batch_size=2, epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0984e8d-b71b-4678-90b6-68703a6d321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e96ee64b-baa4-4f04-ab64-5da42916ae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model_inf = keras.Model(encoder_inputs, encoder_states)\n",
    "decoder_state_input_h = keras.Input(shape=(units,))\n",
    "decoder_state_input_c = keras.Input(shape=(units,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_model_inf = keras.Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs2] + decoder_states2)\n",
    "\n",
    "reverse_target_index = {v:k for k,v in tokenizer_fr.word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0064bb1d-6a7f-49d5-8df6-1315e931c983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining french translation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d69066c-c634-4382-9474-74b04dd759bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_to_french(english_text):\n",
    "    seq = tokenizer_en.texts_to_sequences([english_text.lower()])\n",
    "    seq = keras.utils.pad_sequences(seq, maxlen=input_tensor.shape[1], padding='post')\n",
    "    states_value = encoder_model_inf.predict(seq)\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0,0] = 1  # start with first token\n",
    "\n",
    "    translation = ''\n",
    "    for _ in range(20):\n",
    "        output_tokens, h, c = decoder_model_inf.predict([target_seq] + states_value)\n",
    "        sampled_token_index = np.argmax(output_tokens[0,-1,:])\n",
    "        sampled_word = reverse_target_index.get(sampled_token_index, '')\n",
    "        if sampled_word == '':\n",
    "            break\n",
    "        translation += ' ' + sampled_word\n",
    "        target_seq[0,0] = sampled_token_index\n",
    "        states_value = [h,c]\n",
    "    return translation.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ffa7b69c-30a4-435d-99e3-b02c7d9033b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "van rossum\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "web science des données ia et plus plus plus plus plus plus plus plus plus plus plus plus plus plus\n"
     ]
    }
   ],
   "source": [
    "for ans in answers_en:\n",
    "    a = translate_to_french(ans)\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bdc761-cbec-434c-9d2f-2ebc66596129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# integration of french and translation with QA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "607942e7-bbf4-4ecb-bfcb-9d89002cb290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question, context):\n",
    "    english_answer = get_answer_english(question, context)\n",
    "    french_answer = translate_to_french(english_answer)\n",
    "    return english_answer, french_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8141a6d7-b34e-429a-8314-5619cccf1697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Q: Who created Python?\n",
      "Answer (English): guido van rossum\n",
      "Answer (French): van rossum\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Q: When was Python first released?\n",
      "Answer (English): 1991\n",
      "Answer (French): \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "Q: What is Python used for?\n",
      "Answer (English): web development, data science, ai, and more\n",
      "Answer (French): web\n"
     ]
    }
   ],
   "source": [
    "for q in questions:\n",
    "    eng_ans, fr_ans = ask_question(q, context)\n",
    "    print(f\"Q: {q}\")\n",
    "    print(f\"Answer (English): {eng_ans}\")\n",
    "    print(f\"Answer (French): {fr_ans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabf4cd7-8cea-4890-9572-7bdd1ce0c0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, user can give any input(question in english) in the context he wants by typing and get right output(answer in french)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "403a9230-8948-41de-b3fb-e53057c33c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your question in English:  When was Python first released?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "English Answer: 1991\n",
      "French Answer: \n"
     ]
    }
   ],
   "source": [
    "user_q = input(\"Enter your question in English: \")\n",
    "eng_ans, fr_ans = ask_question(user_q, context)\n",
    "print(f\"English Answer: {eng_ans}\")\n",
    "print(f\"French Answer: {fr_ans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6bccc1-ad3b-4e90-a5f8-ce3561bd99b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
